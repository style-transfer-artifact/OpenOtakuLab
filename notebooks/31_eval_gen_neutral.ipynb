{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3b6131e",
   "metadata": {},
   "source": [
    "# Neutral Sentence Generation (Evaluate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b752a224",
   "metadata": {},
   "source": [
    "## Load Style Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f7e370b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raidenShogun Responses: 558\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from typing import List\n",
    "import json\n",
    "\n",
    "HARUHI_PATH = Path(r\"..\\Dataset\\Haruhi\\Haruhi_clean.jsonl\")\n",
    "\n",
    "# Check if Dataset exist\n",
    "assert HARUHI_PATH.is_file(), \"请确保 Haruhi Dataset 的路径正确！\"\n",
    "\n",
    "# Load Haruhi Dataset\n",
    "dataset_lines = HARUHI_PATH.read_text(encoding=\"utf-8\").splitlines()\n",
    "\n",
    "raidenShogun_responses: List[str] = []\n",
    "\n",
    "for line in dataset_lines:\n",
    "    item = json.loads(line)\n",
    "\n",
    "    # 只提取单一角色的训练集\n",
    "    if item[\"agent_role\"] == \"雷电将军\":\n",
    "        raidenShogun_responses.append(item[\"agent_response\"])\n",
    "\n",
    "# 输出所有训练集的长度\n",
    "\n",
    "print(f\"raidenShogun Responses: {len(raidenShogun_responses)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3189fdb9",
   "metadata": {},
   "source": [
    "## Initialize LLM Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95d2232d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional, Dict, Any, Sequence, Tuple, Iterable\n",
    "\n",
    "from openai import OpenAI\n",
    "from openai.types.chat import ChatCompletionMessageParam as ChatMsgParam\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # 从 .env 文件加载环境变量\n",
    "\n",
    "# === 配置项 ===\n",
    "DEFAULT_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"sk-PLACEHOLDER\")\n",
    "DEFAULT_BASE_URL = os.getenv(\"OPENAI_BASE_URL\", \"https://dashscope.aliyuncs.com/compatible-mode/v1\")\n",
    "DEFAULT_MODEL = os.getenv(\"NEUTRAL_MODEL\", \"qwen3-max-2025-09-23\")\n",
    "DEFAULT_SYSTEM_PROMPT = \"你是一个语言风格分析专家，你需要根据通过一个带有特定角色风格的句子，改写为语义相同但风格中性的版本。要求不使用任何语气词、感叹词或修辞；不体现说话者的性格、情绪或身份；使用普通的书面语或口语表达\"\n",
    "\n",
    "ConversationTurn = Tuple[str, Optional[str]]\n",
    "\"\"\"表示一次对话轮次：(user_message, assistant_reply)。assistant_reply 可为 None。\"\"\"\n",
    "\n",
    "\n",
    "def _build_messages(\n",
    "    prompt: str,\n",
    "    history: Optional[Sequence[ConversationTurn]] = None,\n",
    "    system_prompt: Optional[str] = None,\n",
    ") -> list[ChatMsgParam]:\n",
    "    messages: list[ChatMsgParam] = []\n",
    "\n",
    "    if system_prompt:\n",
    "        messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "\n",
    "    if history:\n",
    "        for user_msg, assistant_msg in history:\n",
    "            messages.append({\"role\": \"user\", \"content\": user_msg})\n",
    "            if assistant_msg:\n",
    "                messages.append({\"role\": \"assistant\", \"content\": assistant_msg})\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    return messages\n",
    "\n",
    "\n",
    "@dataclass(slots=True)\n",
    "class SimpleLLMClient:\n",
    "    \"\"\"极简 LLM 封装：初始化固定模型，提供 ask() 返回字符串。\"\"\"\n",
    "\n",
    "    model: str = DEFAULT_MODEL\n",
    "    api_key: str = DEFAULT_API_KEY\n",
    "    base_url: Optional[str] = DEFAULT_BASE_URL\n",
    "    system_prompt: Optional[str] = DEFAULT_SYSTEM_PROMPT\n",
    "    extra_headers: Optional[Dict[str, str]] = None\n",
    "    _client: OpenAI = field(init=False, repr=False)\n",
    "\n",
    "    def __post_init__(self) -> None:\n",
    "        self._client = OpenAI(\n",
    "            api_key=self.api_key,\n",
    "            base_url=self.base_url,\n",
    "            default_headers=self.extra_headers if self.extra_headers else None,\n",
    "        )\n",
    "\n",
    "    def _consume_stream(self, stream_resp: Iterable[Any]) -> str:\n",
    "        \"\"\"消费流式响应，拼接内容。\"\"\"\n",
    "        chunks: list[str] = []\n",
    "        for chunk in stream_resp:\n",
    "            choices = getattr(chunk, \"choices\", None)\n",
    "            if not choices:\n",
    "                continue\n",
    "            delta = getattr(choices[0], \"delta\", None)\n",
    "            if delta and getattr(delta, \"content\", None):\n",
    "                chunks.append(delta.content)\n",
    "        return \"\".join(chunks)\n",
    "\n",
    "    def ask(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        history: Optional[Sequence[ConversationTurn]] = None,\n",
    "        *,\n",
    "        temperature: float = 0.7,\n",
    "        top_p: float = 0.9,\n",
    "        max_tokens: Optional[int] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> str:\n",
    "        \"\"\"生成回复。\n",
    "\n",
    "        参数：\n",
    "            prompt: 当前用户输入。\n",
    "            history: 可选的历史 [(user, assistant), ...]，assistant 允许为 None。\n",
    "            temperature/max_tokens/stream/kwargs：直接透传给 OpenAI Chat Completion。\n",
    "        返回：\n",
    "            模型回复的纯文本（若响应为空则返回空字符串）。\n",
    "        \"\"\"\n",
    "        messages = _build_messages(\n",
    "            prompt=prompt,\n",
    "            history=history,\n",
    "            system_prompt=self.system_prompt,\n",
    "        )\n",
    "\n",
    "        response = self._client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=messages,\n",
    "            temperature=temperature,\n",
    "            max_tokens=max_tokens,\n",
    "            top_p=top_p,\n",
    "            stream=False,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "        choice = response.choices[0]\n",
    "        if hasattr(choice, \"message\") and getattr(choice.message, \"content\", None):\n",
    "            return choice.message.content  # type: ignore[return-value]\n",
    "        # 兼容历史版本/异常情况\n",
    "        return getattr(choice, \"text\", \"\")\n",
    "\n",
    "\n",
    "# 初始化一个通用实例，供 Notebook 其他单元直接调用\n",
    "llm = SimpleLLMClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacfeb41",
   "metadata": {},
   "source": [
    "## Call LLM to Generate Neutral Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7d4715a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating 雷电将军 neutral sentences: 100%|██████████| 558/558 [09:34<00:00,  1.03s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from time import sleep\n",
    "from typing import Dict, Optional, Sequence\n",
    "from tqdm import tqdm\n",
    "\n",
    "DEFAULT_TEMPERATURE = float(os.getenv(\"NEUTRAL_TEMPERATURE\", \"0.2\"))\n",
    "DEFAULT_SLEEP_SECONDS = float(os.getenv(\"NEUTRAL_SLEEP_SECONDS\", \"0.3\"))\n",
    "\n",
    "SHOTS_EXAMPLE = [(\"风格句: 我今晚吃了楠符电池呢！你要不要也来一块？（递上）\\n中性句: \", \"我今天吃了电池。\"), (\"风格句: 我才不是什么地雷女呢，只是长得像而已...\\n中性句: \", \"我不是地雷女。\")]\n",
    "\n",
    "\n",
    "def build_neutral_prompt(stylized_text: str) -> str:\n",
    "    \"\"\"根据带风格的原句构造改写提示。\"\"\"\n",
    "    return (\n",
    "        f\"风格句: {stylized_text}\\n\"\n",
    "        \"中性句: \"\n",
    "    )\n",
    "\n",
    "\n",
    "def generate_neutral_corpus_with_CoT(\n",
    "    stylized_texts: Sequence[str],\n",
    "    character: Optional[str] = None,\n",
    "    *,\n",
    "    limit: Optional[int] = None,\n",
    "    temperature: float = DEFAULT_TEMPERATURE,\n",
    "    sleep_seconds: float = DEFAULT_SLEEP_SECONDS,\n",
    ") -> list[Dict[str, str]]:\n",
    "    \"\"\"调用 llm.ask 批量生成中性句。\"\"\"\n",
    "    records: list[Dict[str, str]] = []\n",
    "\n",
    "    for idx, text in enumerate(tqdm(stylized_texts, desc=f\"Generating {character} neutral sentences\", total=limit or len(stylized_texts))):\n",
    "        if limit is not None and idx >= limit:\n",
    "            break\n",
    "\n",
    "        neutral_sentence = llm.ask(prompt=build_neutral_prompt(text), history=None, temperature=temperature).strip()\n",
    "        records.append({\"original\": text, \"neutral\": neutral_sentence})\n",
    "        \n",
    "        sleep(sleep_seconds)\n",
    "\n",
    "    return records\n",
    "\n",
    "\n",
    "raidenShogun_responses_records = generate_neutral_corpus_with_CoT(raidenShogun_responses, \"雷电将军\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0891fad2",
   "metadata": {},
   "source": [
    "## Data Cleaning (Evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efd19848",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_records = []\n",
    "blacklist = [\"雷电将军\", \"雷电\", \"将军\", \"稻妻\"]\n",
    "\n",
    "for records in raidenShogun_responses_records:\n",
    "    if not any(blacklisted in records[\"neutral\"] for blacklisted in blacklist):\n",
    "        valid_records.append(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3b9264",
   "metadata": {},
   "source": [
    "## Export Neutral Sentence Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7365dde2",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "final_outputs = []\n",
    "\n",
    "def save_records(character: str, records: list[Dict[str, str]]):\n",
    "    for record in records:\n",
    "        final_outputs.append({\n",
    "            \"character\": character,\n",
    "            \"original\": record[\"original\"],\n",
    "            \"neutral\": record[\"neutral\"]\n",
    "        })\n",
    "\n",
    "save_records(\"raidenShogun\", valid_records)\n",
    "\n",
    "# 输出到 JSONL 文件\n",
    "output_path = Path(\"./data/neutral_sentences_eval.jsonl\")\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "with output_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    for item in final_outputs:\n",
    "        f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Paper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}